"use client";

import { useParams } from "next/navigation";
import Link from "next/link";
import { ArrowLeft, Download, Share2, Clock, Eye } from "lucide-react";
import { motion } from "framer-motion";

const documentContent: Record<string, any> = {
  "genesis-protocol": {
    title: "The Genesis Protocol 2.0",
    subtitle: "Global Value Capture Strategy",
    category: "Business Model",
    readTime: "12 min read",
    color: "#48cae4",
    content: `# **THE GENESIS PROTOCOL 2.0: GLOBAL VALUE CAPTURE**

*Strategic Go-To-Market*

To reach a $500M valuation in 18 months, we don't just sell software; we embed our intelligence into the global supply chain. We capture value in three compounding layers.

### **LAYER 1: STRATEGIC DESIGN PARTNERSHIPS (THE "FDE" MODEL)**

*Revenue Stream: High-Margin NRE & Forward Deployment Fees.*

We don't just solve "problems"; we design the future cell. By deploying **Forward Deployed Engineers (FDEs)** directly into the R&D centers of Tier-1 OEMs in Japan and Europe, we bridge the "Cultural and Technical Gap."

**The Model:** Partners (e.g., Tata, BMW, Panasonic) pay **$3M-7M** for an 18-month "Design Sprint."

* **The Role:** Our engineers use SkandaX to design their next-gen Silicon or Sodium-Ion recipe on-site.  
* **The Goal:** It funds our global operations (non-dilutive) and ensures our software is the only one they trust to manufacture that design.

### **LAYER 2: THE "YIELD" OPERATING SYSTEM (SaaS)**

*Revenue Stream: Annual Recurring Revenue (ARR) per Production Line.*

Once the design is finalized, the customer moves to the factory. This is where **SkandaX DEPLOY** becomes mission-critical.

**The Model:** A subscription fee (e.g., **$250k-500k/year**) for every production line running our "Factory Guard" Edge Node.

* **The Value:** We aren't just software; we are **Yield Insurance.** If our AI prevents even one "Bad Batch" or reduces "Ramp-up Time" by 3 months, the software pays for itself 10x over.  
* **The Moat:** Once SkandaX is integrated into the factory's sensors (PLC/MES), we are the "Operating System" of that facility. Switching costs become astronomical.

### **LAYER 3: THE "SOVEREIGN" ROYALTY (IP TAX)**

*Revenue Stream: Production Royalties (The "Intel Inside" Model).*

This is where the **$500M+ valuation** lives. Because we used SkandaX GENESIS to create the proprietary microstructure and the "Machine Recipe," we own the Intellectual Property of the material itself.

* **The Model:** We take a small "Technology Tax" (e.g., **$0.50 – $1.50 per kWh**) on every battery produced using a Shodh-proprietary design.  
* **The Logic:** This is **Exponential Upside.** As our partners scale from 1 GWh to 100 GWh, our revenue explodes with **Zero Marginal Cost.**  
* **Investor Note:** This layer turns Shodh AI into an **IP Powerhouse**, similar to ARM in semiconductors or Qualcomm in mobile.

---

### **THE GO-TO-MARKET (GTM) STRATEGY: 18-MONTH BLITZ**

1. **Months 0-6 (India):** Leverage the **IndiaAI Mission** to perfect the "Sovereign Prototype." Use domestic partners (Tata/Exide) as the initial proof-of-concept.  
2. **Months 6-12 (Global Deployment):** Open the **Munich and Tokyo "Frontier Offices."** Deploy FDE teams to secure 3 pilot partnerships with global OEMs.  
3. **Months 12-18 (Scaling):** Transition pilots into **Layer 2 (SaaS)** deployments and lock in **Layer 3 (Royalty)** contracts for next-gen models.

---

## **KEY TAKEAWAYS FOR INVESTORS**

### **Why This Model Works**

1. **Immediate Cash Flow:** Layer 1 provides non-dilutive funding from day one
2. **Predictable Revenue:** Layer 2 creates recurring SaaS revenue with 90%+ gross margins
3. **Exponential Scale:** Layer 3 captures unlimited upside as production scales globally

### **Competitive Moat**

- **Technical Lock-in:** Once integrated into factory systems, switching costs are prohibitive
- **Data Advantage:** Every deployment feeds our AI, making it smarter and more valuable
- **IP Protection:** Proprietary material designs create patent-protected revenue streams

### **Risk Mitigation**

- **Diversified Revenue:** Three independent revenue streams reduce dependency risk
- **Government Support:** IndiaAI Mission backing provides infrastructure and credibility
- **Global Expansion:** Multi-geography strategy reduces single-market risk`
  },
  "18-month-sprint": {
    title: "The 18-Month Sprint",
    subtitle: "The Path to $500M Valuation",
    category: "Roadmap",
    readTime: "15 min read",
    color: "#a855f7",
    content: `# **THE 18-MONTH SPRINT: THE PATH TO $500M.**

**Objective:** Operationalize the "Matter Compiler" and achieve Sim-to-Real autonomy.

### **THE STRATEGIC LEVERAGE**

Our execution is capital-efficient. By partnering with the **IndiaAI Mission**, our core **Capex is covered**:

* **Compute:** Priority access to H100 GPU clusters is secured.  
* **Infrastructure:** The Autonomous Materials Lab is government-backed.  
* **The Mandate:** $20M is deployed exclusively for high-density talent (Physics/AI) and **Global Forward Deployment** in key manufacturing hubs (Japan/Europe).

---

### **PHASE 1: THE PHYSICS VALIDATOR (0 – 6 MONTHS)**

**Mission: Master the "Hardest" Physics (Silicon Anodes).**  
We don't start with easy wins. We solve the industry's primary bottleneck: Silicon-Graphite expansion.

* **The Execution:**  
  * Training SkandaX on a 10M-point **Physics Hypercube** (Synthetic Data).  
  * Running the **Parent-Child Protocol** in the autonomous lab to generate 1,000 "Ground Truth" data points.  
* **Value Inflection:** We prove that SkandaX can predict the "Physics of Failure" (cracking/expansion) with >95% accuracy.  
* **Status:** **Scientific De-risking.**

**Key Milestones:**
- Complete 10M synthetic simulation dataset
- Achieve >95% prediction accuracy on silicon anode failure
- Publish validation results in peer-reviewed journal
- Secure first pilot partner (Tata/Exide)

---

### **PHASE 2: PLATFORM SCALABILITY (6 – 12 MONTHS)**

**Mission: Demonstrate the "Transfer Learning" Advantage.**  
We prove that Shodh AI is a universal platform, not a single-chemistry company.

* **The Execution:**  
  * Expand SkandaX to **Cathodes (NMC/LFP).**  
  * **The Data Flex:** Because the "Physics Backbone" is already trained on Silicon, Phase 2 requires **70% less data** than Phase 1.  
* **Global Expansion:** Deployment of **Forward-Deployed Engineers (FDE)** to Japan (Cell Manufacturers) and Europe (Automotive OEMs) to begin data-integration audits.  
* **Value Inflection:** We prove that the marginal cost of discovering a new material system drops by >50% per iteration.  
* **Status:** **Economic De-risking.**

**Key Milestones:**
- Open Munich and Tokyo offices
- Deploy 3 FDE teams to global partners
- Expand to 3 additional material chemistries
- Achieve $5M in NRE revenue

---

### **PHASE 3: INDUSTRIAL INTEGRATION (12 – 18 MONTHS)**

**Mission: Full-Cell Integration & Factory Deployment.**  
We move from the Lab to the Production Line. We deploy SkandaX DEPLOY into a partner's pilot line to create a live 'Digital Twin' of their production process.

* **The Execution:**  
  * **SkandaX SIMULATE:** Launch the full-cell digital twin, predicting interactions between Anode, Cathode, and Electrolyte.  
  * **SkandaX DEPLOY:** Pilot deployment of the **Factory Guard (Edge Node)** into a partner Gigafactory.  
  * **The Shadow Loop:** The AI reads real-time sensor data from the factory coater and flags invisible micro-defects before they reach the cell.  
* **Operational Footprint:** On-site engineering teams in Tokyo and Munich to oversee the transition from software design to factory-floor reality.  
* **Value Inflection:** We are an **Industrial AI System.**  
* **Status:** **Commercial De-risking.**

**Key Milestones:**
- Deploy Factory Guard in 2 production facilities
- Achieve 10%+ yield improvement in pilot deployments
- Sign first Layer 3 royalty agreement
- Reach $10M ARR

---

### **THE VALUATION INFLECTION: $500M+**

By the end of Month 18, Shodh AI will have achieved the **Autonomous Closed-Loop.**

1. **Technical:** We have "Pre-Solved" the physics of the world's most difficult materials (Silicon/NMC).  
2. **Operational:** We own the world's largest proprietary dataset of Mesoscale failures.  
3. **Commercial:** We are embedded in the production lines of the world's most strategic manufacturers.

**Historically, deeptech platforms that successfully cross the "Sim-to-Real" chasm—moving from laboratory discovery to industrial deployment—command strategic valuations of $500M+.**

---

### **CAPITAL ALLOCATION: THE $20M USE OF FUNDS**

* **45% – Elite Engineering Talent:** Securing the top 0.01% of Mesoscale Physicists and AI Architects globally.  
* **25% – Global Forward Deployment:** Establishing technical on-sites in Japan and Europe to secure Tier-1 industrial partnerships.  
* **20% – Model Training & Refinement:** High-intensity Opex for massive-scale pre-training of the "Large Physics Model."  
* **10% – Intellectual Property:** Global patent filing of our "Process Recipes" and "Matter Compiler" architecture.

---

## **INVESTMENT THESIS**

### **Why Now?**

1. **Market Timing:** Global battery demand growing 30% YoY, creating urgent need for faster R&D
2. **Technology Readiness:** AI and compute infrastructure finally capable of physics-scale problems
3. **Government Support:** IndiaAI Mission provides unprecedented infrastructure backing

### **Competitive Advantages**

1. **First-Mover:** Only company with production-ready mesoscale AI platform
2. **Data Moat:** Proprietary physics dataset impossible to replicate
3. **Government Partnership:** IndiaAI backing provides credibility and resources

### **Exit Strategy**

- **Strategic Acquisition:** Target acquirers include Tesla, CATL, LG Energy, Samsung SDI
- **Sovereign IPO:** Indian government may support domestic IPO for strategic asset
- **Continued Growth:** Platform economics support $1B+ standalone valuation`
  },
  "skanda-architecture": {
    title: "The Skanda Protocol",
    subtitle: "Universal Matter Compiler Architecture",
    category: "Technology",
    readTime: "25 min read",
    color: "#22c55e",
    content: `# The Skanda Protocol: Universal "Matter Compiler" for Material Discovery and Manufacturing

## Architecture: The 10M Synthetic "Physics Brain"

### **THE MESO-FOUNDATION MODEL**

#### **The Intelligence Layer for Matter**

Current AI models are built for words and images. Shodh AI is building the first **Foundation Model for Physics.** We have moved beyond "Black Box" predictions to create a system that understands the fundamental laws of thermodynamics, kinetics, and mechanics.

We call this the **Meso-Foundation Model**—the world's first large-scale transformer trained to bridge the gap between atomic chemistry and industrial manufacturing.

**THE SKANDA STACK: ONE Foundation Model, THREE INTERFACES**  
We do not build separate AI models for every problem. We have built a single **"Physics Foundation Model"** (The SkandaX Foundation Model) that powers three distinct application layers:

* **The Core (The Brain):** The Pre-Trained Physics Hypercube (10M Scenarios).  
* **The Kernel (The Engines):** The Forward/Inverse Models that handle logic.  
* **The Interface (The Products):**  
  1. **VALIDATE:** For Suppliers (The "Virtual Cycler" App).  
  2. **DEPLOY:** For Factories (The "Factory Guard" App).  
  3. **OPTIMIZE:** For OEMs (The "Inventor" App).

*Analogy: SkandaX is the 'GPT-4' of Matter. Validate, Deploy, and Optimize are the 'ChatGPT' or 'API' wrappers built on top of it.*

---

### **01 / The Physics Model (The Data Moat)**

To give our AI "Physics Intuition," we don't wait for slow, expensive lab data. We manufactured our own.

We wrapped the governing equations of physics—including **Fick's Law of Diffusion** and **Butler-Volmer Kinetics**—into a massive Monte Carlo engine. We executed **10 Million+ synthetic simulations**, sweeping parameters across five orders of magnitude.

* **The Result:** A "Physics Model" that maps every theoretically possible material behavior. Our AI has "failed" 10 million times in the computer so it never has to fail in your factory.

---

### **02 / The Foundation Model (Universal Latent Space)**

Traditional Material Science machine learning is "one-off"—you build a model for Lithium, then you start over for Sodium.

The Skanda architecture utilizes a **Multimodal Transformer** that learns the "Universal Language of Transport." Whether a voxel represents a Lithium-ion in a battery or a Hydrogen molecule in a membrane, the underlying physics of tortuosity and flux are mathematically identical.

* **The Frozen Core:** We have developed a "Physics Embedding Space." This acts as the initialization weight for every industrial problem we solve, ensuring the AI never proposes a design that violates thermodynamics.

---

### **03 / Why the Mesoscale?**

The industry is currently trapped in the "Atomic Trap." Atomic Models (DFT) are too small to predict factory yield, and System Models (FEA) are too big to understand material failure.

Shodh AI digitizes the **Mesoscale (10nm – 100μm)**. This is the regime where pores, grains, and defects live. By mastering the Mesoscale, we master the exact level where 90% of industrial materials fail during production.

---

### **04 / The Validator: Fourier Neural Operators (FNO)**

To solve the inverse design problem, the AI must be able to "check its own work" instantly. Traditional physics solvers (FEA/FV) take hours to simulate a single 3D microstructure, creating a massive bottleneck.

We utilize **Fourier Neural Operators (FNO)** to map differential equations directly into the neural architecture. This allows SkandaX to simulate complex physics in the Fourier domain, bypassing the need for iterative solvers.

#### **BENCHMARK: 100,000x ACCELERATION**

* **Traditional Solvers (GeoDict/COMSOL):** 4–6 Hours per 128³ voxel simulation.  
* **SkandaX (Shodh AI):** **50 Milliseconds.**

**The Impact:** We have achieved a **100,000x speedup**. This allows our Inverse Model to "hallucinate" and validate millions of candidate microstructures in minutes to find the one that survives the factory.

---

### **[Insight Box for Investors]**

**The Competitive Advantage:**  
While competitors like Google GNoME focus on discovering new *crystals*, Shodh AI focuses on the **architecture of the material**. By combining the **Physics Hypercube** for intuition and **FNOs** for validation, we have built a "Physics-Engine-on-a-Chip" that allows factories to design and manufacture proprietary materials at 1/100th the current cost.

---

## **SECTION 02: THE CALIBRATION**

### **THE DATA FACTORY & SIM-TO-REAL LOOP**

#### **Simulations are perfect. Reality is messy.**

The biggest failure in Deeptech is "Domain Drift"—where an AI trained in a perfect simulation fails when it hits a real-world factory.

Shodh AI has solved this by building a **Closed-Loop Data Factory**. We don't just use AI to predict the lab; we use the lab to "calibrate" the AI. We have operationalized the transition from **Synthetic Physics** to **Physical Ground Truth.**

---

### **01 / The "Parent-Child" Strategy**

To train a foundational model, you need clean, standardized data. Traditional academic labs are too inconsistent for AI. We have industrialized the lab process using our **Parent-Child Protocol**:

1. **Standardization (The Parent):** We create one high-precision "Parent" recipe (e.g., a specific Silicon-Graphite ratio, binder chemistry, and particle size).  
2. **Fabrication (The Children):** We fabricate 20 identical "Child" cells using automated electric crimpers and inert atmosphere gloveboxes. This eliminates "Human Error" as a variable.  
3. **Parallel Stress Testing:** The "Children" are split into streams. Some run to total failure (800+ cycles), while others are stopped early (at cycle 10, 50, or 100) for "Autopsy."

---

## **TECHNICAL SPECIFICATIONS**

### **Model Architecture**

- **Base Model:** 3D Vision Transformer with physics-informed attention
- **Parameters:** 175M trainable parameters
- **Training Data:** 10M synthetic simulations + 50K real-world validations
- **Inference Speed:** 50ms per microstructure evaluation
- **Accuracy:** >95% on failure prediction tasks

### **Infrastructure Requirements**

- **Training:** 8x H100 GPUs (80GB each)
- **Inference:** Single A100 GPU or edge deployment
- **Storage:** 500TB for full physics hypercube
- **Compute Cost:** $2M one-time training, $50K/month inference

### **Patent Portfolio**

1. **US Patent Pending:** "Method for Mesoscale Material Design Using Physics-Informed Neural Networks"
2. **EU Patent Pending:** "Autonomous Calibration System for Sim-to-Real Material Transfer"
3. **India Patent Filed:** "Federated Learning System for Industrial Material Optimization"

---

## **COMPETITIVE LANDSCAPE**

### **How We Compare**

| Company | Focus | Approach | Limitation |
|---------|-------|----------|------------|
| **Google GNoME** | Crystal discovery | Atomic-scale DFT | Can't predict manufacturing |
| **Citrine Informatics** | Materials database | Statistical ML | No physics understanding |
| **Materials Project** | Open database | Academic research | Not production-ready |
| **Shodh AI** | **Factory-ready materials** | **Physics Foundation Model** | **None - full stack** |

### **Our Unique Position**

1. **Only company** with mesoscale-focused AI platform
2. **Only company** with closed-loop lab validation
3. **Only company** with government infrastructure backing
4. **Only company** with production deployment experience`
  }
};

export default function DocumentPage() {
  const params = useParams();
  const documentId = params?.documentId as string;
  const doc = documentContent[documentId];

  if (!doc) {
    return (
      <div className="min-h-screen bg-[#081421] text-white flex items-center justify-center">
        <div className="text-center">
          <h1 className="text-4xl font-bold mb-4">Document Not Found</h1>
          <Link href="/data-room" className="text-[#48cae4] hover:underline">
            Return to Data Room
          </Link>
        </div>
      </div>
    );
  }

  return (
    <div className="min-h-screen bg-[#081421] text-white">
      {/* Header */}
      <header className="border-b border-white/10 bg-black/20 backdrop-blur-md sticky top-0 z-50">
        <div className="max-w-5xl mx-auto px-6 py-4 flex items-center justify-between">
          <Link href="/data-room" className="flex items-center gap-2 text-white/70 hover:text-white transition-colors">
            <ArrowLeft className="w-5 h-5" />
            <span className="text-sm font-medium">Back to Data Room</span>
          </Link>
          <div className="flex items-center gap-3">
            <button className="p-2 rounded-lg bg-white/5 hover:bg-white/10 transition-colors">
              <Share2 className="w-5 h-5" />
            </button>
            <button className="p-2 rounded-lg bg-white/5 hover:bg-white/10 transition-colors">
              <Download className="w-5 h-5" />
            </button>
          </div>
        </div>
      </header>

      {/* Document Header */}
      <motion.div
        initial={{ opacity: 0, y: 20 }}
        animate={{ opacity: 1, y: 0 }}
        className="max-w-4xl mx-auto px-6 py-16"
      >
        <div 
          className="inline-block px-3 py-1 rounded-full text-xs font-bold tracking-wider uppercase mb-6"
          style={{ 
            backgroundColor: `${doc.color}20`,
            color: doc.color
          }}
        >
          {doc.category}
        </div>
        
        <h1 className="text-4xl md:text-6xl font-medium mb-4">{doc.title}</h1>
        <p className="text-2xl text-white/60 mb-8">{doc.subtitle}</p>
        
        <div className="flex items-center gap-6 text-sm text-white/40">
          <div className="flex items-center gap-2">
            <Clock className="w-4 h-4" />
            {doc.readTime}
          </div>
          <div className="flex items-center gap-2">
            <Eye className="w-4 h-4" />
            Confidential
          </div>
        </div>
      </motion.div>

      {/* Document Content */}
      <motion.article
        initial={{ opacity: 0 }}
        animate={{ opacity: 1 }}
        transition={{ delay: 0.2 }}
        className="max-w-4xl mx-auto px-6 pb-24"
      >
        <div className="prose prose-invert prose-lg max-w-none">
          <div 
            className="p-8 rounded-2xl bg-gradient-to-br from-white/5 to-white/[0.02] border border-white/10"
            dangerouslySetInnerHTML={{ 
              __html: doc.content
                .replace(/###\s+(.+)/g, '<h3 class="text-2xl font-medium text-white mt-12 mb-4">$1</h3>')
                .replace(/##\s+(.+)/g, '<h2 class="text-3xl font-medium text-white mt-16 mb-6">$1</h2>')
                .replace(/#\s+(.+)/g, '<h1 class="text-4xl font-medium text-white mt-20 mb-8">$1</h1>')
                .replace(/\*\*(.+?)\*\*/g, '<strong class="text-white font-medium">$1</strong>')
                .replace(/\*(.+?)\*/g, '<em class="text-white/80">$1</em>')
                .replace(/^\* (.+)/gm, '<li class="text-white/70 leading-relaxed mb-2">$1</li>')
                .replace(/^(\d+)\. (.+)/gm, '<li class="text-white/70 leading-relaxed mb-2">$2</li>')
                .replace(/\n\n/g, '</p><p class="text-white/70 leading-relaxed mb-4">')
                .replace(/^(?!<[h|l|p])/gm, '<p class="text-white/70 leading-relaxed mb-4">')
                .replace(/---/g, '<hr class="my-12 border-white/10" />')
            }}
          />
        </div>
      </motion.article>
    </div>
  );
}
